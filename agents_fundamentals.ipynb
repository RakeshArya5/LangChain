{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a bit more deeper into Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational ReAct Agents\n",
    "This agent is designed for use in conversational settings. It incorporates the React framework to determine which tool to use and utilizes memory to remember previous conversation interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_react_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"],  llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=\"conversational-react-description\", \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Add 7 to 9\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 16\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The result of adding 7 to 9 is 16.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: Add 16 to 5\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 21\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The result of adding 5 to the previous result of 16 is 21.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output_1=conversational_agent.run(\"Add 7 to 9 and tell me the result\")\n",
    "output_2=conversational_agent.run(\"Add 5 to the previous result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of adding 7 to 9 is 16.\n",
      "The result of adding 5 to the previous result of 16 is 21.\n"
     ]
    }
   ],
   "source": [
    "print(output_1)\n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Docstore\n",
    "This agent utilizes the React framework to communicate with a docstore. It requires the availability of a Search tool and a Lookup tool with identical names. The Search tool is used to search for a document, while the Lookup tool looks up a term within the most recently found document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `docstore` in Langchain is essentially a storage system for documents. It provides a way for Langchain agents to access and interact with information. Think of it like a library, but instead of books, it holds pieces of text and associated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from Wikipedia) (4.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from Wikipedia) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from beautifulsoup4->Wikipedia) (2.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->Wikipedia) (1.25.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->Wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->Wikipedia) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rakes\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->Wikipedia) (2021.10.8)\n",
      "Building wheels for collected packages: Wikipedia\n",
      "  Building wheel for Wikipedia (setup.py): started\n",
      "  Building wheel for Wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for Wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11689 sha256=be8e3e8c4c7c50518af1625591dddb971922160bd5f4a038d71ce43cbd84faf9\n",
      "  Stored in directory: c:\\users\\rakes\\appdata\\local\\pip\\cache\\wheels\\07\\93\\05\\72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n",
      "Successfully built Wikipedia\n",
      "Installing collected packages: Wikipedia\n",
      "Successfully installed Wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools=[\n",
    "    Tool(name=\"Search\", func=docstore.search, description=\"useful for when you need to search wikipedia\"),\n",
    "    Tool(name=\"Lookup\", func=docstore.lookup, description=\"useful for when you need to lookup a term in wikipedia\")]\n",
    "\n",
    "#intializing the agent\n",
    "llm = OpenAI(temperature=0)\n",
    "docstore_agent=initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"react-docstore\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rakes\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search Elon Musk and find some key information about him.\n",
      "Action: Search[Elon Musk]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mCould not find [Elon Musk]. Similar: ['Elon Musk', 'Twitter under Elon Musk', 'Musk family', 'Acquisition of Twitter by Elon Musk', 'Wealth of Elon Musk', 'Views of Elon Musk', 'Elon Musk (disambiguation)', 'Elon Musk vs. Mark Zuckerberg', \"Elon Musk's Tesla Roadster\", 'Maye Musk']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to be more specific and search for \"Elon Musk entrepreneur\" to find information about his career.\n",
      "Action: Search[Elon Musk entrepreneur]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Musk family is a wealthy family of South African origin that is largely active in the United States and Canada. The Musks are of English, Anglo-Canadian, Pennsylvania Dutch, and Swiss descent. The family is known for its entrepreneurial endeavours. Elon Musk was formerly the wealthiest person in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionaires Index.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Elon Musk is from a wealthy family and is an entrepreneur. He was also the wealthiest person in the world in 2023. I can also mention his companies, such as Tesla and SpaceX.\n",
      "Action: Finish[Elon Musk is an entrepreneur from a wealthy family and was the wealthiest person in the world in 2023. He is the founder of companies such as Tesla and SpaceX.]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me a few key things about Elon Musk.',\n",
       " 'output': 'Elon Musk is an entrepreneur from a wealthy family and was the wealthiest person in the world in 2023. He is the founder of companies such as Tesla and SpaceX.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docstore_agent(\"Tell me a few key things about Elon Musk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-ask with Search\n",
    "This agent utilizes the Intermediate Answer tool for self-asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        func=search.run,\n",
    "        name=\"Intermediate Answer\",\n",
    "        description=\"useful for when you need to search the internet for information\"\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"self-ask-with-search\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Yes.\n",
      "Follow up: When was the superconductor discovered?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFollow up: Who discovered the superconductor?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3mNo good DuckDuckGo Search Result was found\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSo the final answer is: No information available.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Question: Who was the president of US when superconductor was discovered?', 'output': 'No information available.'}\n"
     ]
    }
   ],
   "source": [
    "print(agent.invoke(\"Question: Who was the president of US when superconductor was discovered?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports necessary modules from the LangChain library, including agents and language models. It sets up a conversational agent with a specific agent configuration called “self-ask-with-search”. The agent utilizes the “Intermediate Answer” tool, which performs Wikipedia searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
